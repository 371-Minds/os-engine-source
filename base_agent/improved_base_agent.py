# Create improved BaseAgent implementation with benchmarking recommendations

improved_base_agent_code = '''
"""
371 Minds Operating System - Improved Base Agent Implementation
Incorporates performance optimizations and monitoring capabilities
"""

import asyncio
import json
import logging
import uuid
import time
import weakref
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
from typing import Dict, List, Optional, Any, Callable
from datetime import datetime
from contextlib import asynccontextmanager
from adaptive_llm_router.llm import invoke as alr_invoke

# Performance and monitoring imports
import psutil
from collections import defaultdict, deque
import threading

class AgentType(Enum):
    """Types of agents in the 371 Minds OS"""
    INTELLIGENT_ROUTER = "intelligent_router"
    CODE_GENERATION = "code_generation"
    MARKETING_ASSET = "marketing_asset"
    BUSINESS_LOGIC = "business_logic"
    DEPLOYMENT = "deployment_agent"
    CREDENTIAL_MANAGER = "credential_manager"
    MARKETING_AUTOMATION = "marketing_automation"
    REPOSITORY_INTAKE = "repository_intake"
    QA_AUTOMATION = "qa_automation"
    TECH_STACK_SPECIALIST = "tech_stack_specialist"
    AGENT_UTILITY_BELT = "agent_utility_belt"
    CEO = "ceo"
    CTO = "cto"
    CMO = "cmo"
    CFO = "cfo"
    CLO = "clo"
    FINANCIAL = "financial"

class TaskStatus(Enum):
    """Status of tasks in the system"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    REQUIRES_HUMAN_APPROVAL = "requires_human_approval"
    PROVISIONING = "provisioning"
    DEPLOYING = "deploying"
    CONFIGURING = "configuring"
    FINALIZING = "finalizing"
    QUEUED = "queued"
    RETRYING = "retrying"

@dataclass
class Task:
    """Enhanced task with performance metrics"""
    id: str
    description: str
    agent_type: AgentType
    payload: Dict[str, Any]
    status: TaskStatus = TaskStatus.PENDING
    created_at: datetime = field(default_factory=datetime.now)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    result: Optional[Dict[str, Any]] = None
    requires_human_approval: bool = False
    human_approval_message: Optional[str] = None
    priority: int = 5  # 1 (highest) to 10 (lowest)
    retry_count: int = 0
    max_retries: int = 3
    timeout_seconds: Optional[int] = 300
    
    @property
    def processing_time(self) -> Optional[float]:
        """Calculate task processing time in seconds"""
        if self.started_at and self.completed_at:
            return (self.completed_at - self.started_at).total_seconds()
        return None

@dataclass
class PerformanceMetrics:
    """Agent performance metrics"""
    tasks_completed: int = 0
    tasks_failed: int = 0
    total_processing_time: float = 0.0
    avg_response_time: float = 0.0
    current_memory_mb: float = 0.0
    peak_memory_mb: float = 0.0
    cpu_usage_percent: float = 0.0
    error_rate: float = 0.0
    throughput: float = 0.0  # tasks per second
    cache_hits: int = 0
    cache_misses: int = 0
    
    def update_response_time(self, processing_time: float):
        """Update average response time"""
        total_tasks = self.tasks_completed + self.tasks_failed
        if total_tasks > 0:
            self.total_processing_time += processing_time
            self.avg_response_time = self.total_processing_time / total_tasks
    
    def calculate_error_rate(self) -> float:
        """Calculate current error rate"""
        total_tasks = self.tasks_completed + self.tasks_failed
        if total_tasks > 0:
            self.error_rate = (self.tasks_failed / total_tasks) * 100
        return self.error_rate

class ConnectionPool:
    """Simple connection pool for LLM API calls"""
    def __init__(self, max_connections: int = 10):
        self.max_connections = max_connections
        self.available_connections = asyncio.Queue(maxsize=max_connections)
        self.active_connections = 0
        self._lock = asyncio.Lock()
        
    async def get_connection(self):
        """Get a connection from the pool"""
        async with self._lock:
            if self.active_connections < self.max_connections:
                self.active_connections += 1
                return f"connection_{self.active_connections}"
            else:
                # Wait for available connection
                return await self.available_connections.get()
    
    async def return_connection(self, connection):
        """Return a connection to the pool"""
        await self.available_connections.put(connection)

class SimpleCache:
    """Simple TTL cache for agent responses"""
    def __init__(self, max_size: int = 1000, ttl_seconds: int = 3600):
        self.cache: Dict[str, tuple] = {}  # key: (value, expiry_time)
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self.access_times = deque()
        
    def get(self, key: str) -> Optional[Any]:
        """Get value from cache"""
        if key in self.cache:
            value, expiry_time = self.cache[key]
            if time.time() < expiry_time:
                return value
            else:
                # Expired
                del self.cache[key]
        return None
    
    def set(self, key: str, value: Any):
        """Set value in cache"""
        # Clean up expired entries and enforce size limit
        current_time = time.time()
        if len(self.cache) >= self.max_size:
            # Remove oldest entries
            keys_to_remove = []
            for k, (v, expiry) in self.cache.items():
                if current_time >= expiry:
                    keys_to_remove.append(k)
                if len(keys_to_remove) >= self.max_size // 4:  # Remove 25% when full
                    break
                    
            for k in keys_to_remove:
                del self.cache[k]
        
        expiry_time = current_time + self.ttl_seconds
        self.cache[key] = (value, expiry_time)

class CircuitBreaker:
    """Simple circuit breaker for external API calls"""
    def __init__(self, failure_threshold: int = 5, timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.is_open = False
    
    def can_execute(self) -> bool:
        """Check if circuit breaker allows execution"""
        if not self.is_open:
            return True
            
        if self.last_failure_time and (time.time() - self.last_failure_time) > self.timeout:
            self.is_open = False
            self.failure_count = 0
            return True
            
        return False
    
    def record_success(self):
        """Record successful execution"""
        self.failure_count = 0
        self.is_open = False
    
    def record_failure(self):
        """Record failed execution"""
        self.failure_count += 1
        self.last_failure_time = time.time()
        
        if self.failure_count >= self.failure_threshold:
            self.is_open = True

class TaskQueue:
    """Priority-based task queue with concurrency control"""
    def __init__(self, max_concurrent_tasks: int = 10):
        self.queue = asyncio.PriorityQueue()
        self.semaphore = asyncio.Semaphore(max_concurrent_tasks)
        self.active_tasks: Dict[str, Task] = {}
        self.completed_tasks = deque(maxlen=1000)  # Keep last 1000 completed tasks
        
    async def add_task(self, task: Task):
        """Add task to queue"""
        task.status = TaskStatus.QUEUED
        # Use negative priority for max-heap behavior (lower number = higher priority)
        await self.queue.put((-task.priority, task.created_at, task))
    
    async def get_task(self) -> Task:
        """Get next task from queue"""
        _, _, task = await self.queue.get()
        return task
    
    def mark_active(self, task: Task):
        """Mark task as active"""
        self.active_tasks[task.id] = task
        
    def mark_completed(self, task: Task):
        """Mark task as completed"""
        if task.id in self.active_tasks:
            del self.active_tasks[task.id]
        self.completed_tasks.append(task)

class ImprovedBaseAgent(ABC):
    """Enhanced base agent with performance optimizations and monitoring"""
    
    def __init__(
        self, 
        agent_id: str, 
        agent_type: AgentType, 
        max_concurrent_tasks: int = 5,
        enable_caching: bool = True,
        enable_circuit_breaker: bool = True
    ):
        self.agent_id = agent_id
        self.agent_type = agent_type
        self.logger = logging.getLogger(f"{agent_type.value}_{agent_id}")
        
        # Performance enhancements
        self.task_queue = TaskQueue(max_concurrent_tasks)
        self.connection_pool = ConnectionPool(max_connections=10)
        self.metrics = PerformanceMetrics()
        self.process = psutil.Process() if psutil else None
        
        # Optional features
        self.cache = SimpleCache() if enable_caching else None
        self.circuit_breaker = CircuitBreaker() if enable_circuit_breaker else None
        
        # Worker management
        self.workers_started = False
        self.shutdown_event = asyncio.Event()
        self.worker_tasks: List[asyncio.Task] = []
        
    async def start_workers(self):
        """Start background worker tasks"""
        if self.workers_started:
            return
            
        # Start worker coroutines
        for i in range(self.task_queue.semaphore._value):
            worker_task = asyncio.create_task(self._worker_loop(f"worker_{i}"))
            self.worker_tasks.append(worker_task)
            
        # Start metrics collection
        metrics_task = asyncio.create_task(self._metrics_loop())
        self.worker_tasks.append(metrics_task)
        
        self.workers_started = True
        self.logger.info(f"Started {len(self.worker_tasks)} workers for agent {self.agent_id}")
    
    async def stop_workers(self):
        """Stop all worker tasks"""
        self.shutdown_event.set()
        
        if self.worker_tasks:
            await asyncio.gather(*self.worker_tasks, return_exceptions=True)
            self.worker_tasks.clear()
            
        self.workers_started = False
        self.logger.info(f"Stopped all workers for agent {self.agent_id}")
    
    async def _worker_loop(self, worker_name: str):
        """Main worker loop for processing tasks"""
        while not self.shutdown_event.is_set():
            try:
                # Get semaphore permission
                async with self.task_queue.semaphore:
                    try:
                        # Get next task with timeout
                        task = await asyncio.wait_for(self.task_queue.get_task(), timeout=1.0)
                        
                        # Process the task
                        await self._execute_task_with_monitoring(task)
                        
                    except asyncio.TimeoutError:
                        # No tasks available, continue loop
                        continue
                        
            except Exception as e:
                self.logger.error(f"Error in worker {worker_name}: {e}")
                await asyncio.sleep(1)  # Prevent tight error loop
    
    async def _execute_task_with_monitoring(self, task: Task):
        """Execute task with comprehensive monitoring"""
        task.status = TaskStatus.IN_PROGRESS
        task.started_at = datetime.now()
        self.task_queue.mark_active(task)
        
        try:
            self.logger.info(f"Starting task {task.id}: {task.description}")
            
            # Check circuit breaker
            if self.circuit_breaker and not self.circuit_breaker.can_execute():
                raise Exception("Circuit breaker is open - service unavailable")
            
            # Execute the task with timeout
            try:
                if task.timeout_seconds:
                    result = await asyncio.wait_for(
                        self.process_task(task),
                        timeout=task.timeout_seconds
                    )
                else:
                    result = await self.process_task(task)
                
                # Task completed successfully
                task.result = result
                task.status = TaskStatus.COMPLETED
                task.completed_at = datetime.now()
                
                # Update metrics
                self.metrics.tasks_completed += 1
                if task.processing_time:
                    self.metrics.update_response_time(task.processing_time)
                
                # Record success for circuit breaker
                if self.circuit_breaker:
                    self.circuit_breaker.record_success()
                
                self.logger.info(f"Completed task {task.id}")
                
            except asyncio.TimeoutError:
                # Task timed out - schedule for retry if possible
                if task.retry_count < task.max_retries:
                    task.retry_count += 1
                    task.status = TaskStatus.RETRYING
                    await asyncio.sleep(2 ** task.retry_count)  # Exponential backoff
                    await self.task_queue.add_task(task)
                    self.logger.warning(f"Task {task.id} timed out, retrying ({task.retry_count}/{task.max_retries})")
                else:
                    task.status = TaskStatus.FAILED
                    task.result = {"error": "Task timed out after maximum retries"}
                    self.metrics.tasks_failed += 1
                    
        except Exception as e:
            # Task failed
            self.logger.error(f"Failed to process task {task.id}: {str(e)}")
            
            # Record failure for circuit breaker
            if self.circuit_breaker:
                self.circuit_breaker.record_failure()
            
            # Check for retry
            if task.retry_count < task.max_retries:
                task.retry_count += 1
                task.status = TaskStatus.RETRYING
                await asyncio.sleep(2 ** task.retry_count)  # Exponential backoff
                await self.task_queue.add_task(task)
                self.logger.warning(f"Task {task.id} failed, retrying ({task.retry_count}/{task.max_retries})")
            else:
                task.status = TaskStatus.FAILED
                task.result = {"error": str(e)}
                task.completed_at = datetime.now()
                self.metrics.tasks_failed += 1
                
                if task.processing_time:
                    self.metrics.update_response_time(task.processing_time)
        
        finally:
            self.task_queue.mark_completed(task)
    
    async def _metrics_loop(self):
        """Background metrics collection loop"""
        while not self.shutdown_event.is_set():
            try:
                await self._update_system_metrics()
                await asyncio.sleep(10)  # Update metrics every 10 seconds
            except Exception as e:
                self.logger.error(f"Error updating metrics: {e}")
                await asyncio.sleep(10)
    
    async def _update_system_metrics(self):
        """Update system resource metrics"""
        if not self.process:
            return
            
        try:
            memory_info = self.process.memory_info()
            current_memory = memory_info.rss / 1024 / 1024  # MB
            
            self.metrics.current_memory_mb = current_memory
            if current_memory > self.metrics.peak_memory_mb:
                self.metrics.peak_memory_mb = current_memory
                
            self.metrics.cpu_usage_percent = self.process.cpu_percent(interval=None)
            
            # Calculate throughput (tasks per second over last minute)
            completed_in_last_minute = len([
                task for task in self.task_queue.completed_tasks 
                if task.completed_at and 
                (datetime.now() - task.completed_at).total_seconds() < 60
            ])
            self.metrics.throughput = completed_in_last_minute / 60.0
            
            # Update error rate
            self.metrics.calculate_error_rate()
            
        except Exception as e:
            self.logger.warning(f"Failed to update system metrics: {e}")
    
    async def llm_invoke_with_pooling(self, prompt: str, meta: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Enhanced LLM invocation with connection pooling and caching"""
        if meta is None:
            meta = {}
            
        # Generate cache key
        cache_key = None
        if self.cache:
            cache_key = f"{hash(prompt)}_{hash(str(sorted(meta.items())))}"
            cached_result = self.cache.get(cache_key)
            if cached_result:
                self.metrics.cache_hits += 1
                return cached_result
            self.metrics.cache_misses += 1
        
        # Get connection from pool
        connection = await self.connection_pool.get_connection()
        
        try:
            # Enrich metadata
            meta["agent_name"] = self.agent_type.value
            meta["agent_id"] = self.agent_id
            
            # Make LLM call
            result = await alr_invoke(prompt, meta, user_id=self.agent_id)
            
            # Cache result if caching is enabled
            if self.cache and cache_key:
                self.cache.set(cache_key, result)
            
            return result
            
        finally:
            # Return connection to pool
            await self.connection_pool.return_connection(connection)
    
    async def submit_task(self, task: Task) -> str:
        """Submit a task for processing"""
        if not self.workers_started:
            await self.start_workers()
            
        await self.task_queue.add_task(task)
        self.logger.info(f"Task {task.id} submitted to queue")
        return task.id
    
    def get_metrics(self) -> PerformanceMetrics:
        """Get current performance metrics"""
        return self.metrics
    
    def get_status(self) -> Dict[str, Any]:
        """Get comprehensive agent status"""
        return {
            "agent_id": self.agent_id,
            "agent_type": self.agent_type.value,
            "workers_started": self.workers_started,
            "active_tasks": len(self.task_queue.active_tasks),
            "queued_tasks": self.task_queue.queue.qsize(),
            "completed_tasks": len(self.task_queue.completed_tasks),
            "metrics": {
                "tasks_completed": self.metrics.tasks_completed,
                "tasks_failed": self.metrics.tasks_failed,
                "avg_response_time": self.metrics.avg_response_time,
                "error_rate": self.metrics.error_rate,
                "throughput": self.metrics.throughput,
                "current_memory_mb": self.metrics.current_memory_mb,
                "cpu_usage_percent": self.metrics.cpu_usage_percent,
                "cache_hit_rate": (self.metrics.cache_hits / (self.metrics.cache_hits + self.metrics.cache_misses) * 100) if (self.metrics.cache_hits + self.metrics.cache_misses) > 0 else 0
            },
            "circuit_breaker_open": self.circuit_breaker.is_open if self.circuit_breaker else False
        }
    
    # Abstract methods that must be implemented by concrete agents
    @abstractmethod
    async def process_task(self, task: Task) -> Dict[str, Any]:
        """Process a task and return the result"""
        pass
    
    @abstractmethod
    async def health_check(self) -> bool:
        """Check if the agent is healthy and ready to process tasks"""
        pass
    
    # Cleanup
    async def shutdown(self):
        """Gracefully shutdown the agent"""
        self.logger.info(f"Shutting down agent {self.agent_id}")
        await self.stop_workers()
'''

print("üìù IMPROVED BASE AGENT IMPLEMENTATION")
print("="*60)
print("‚úÖ Created enhanced BaseAgent with the following improvements:")
print("\nüöÄ PERFORMANCE OPTIMIZATIONS:")
improvements = [
    "‚Ä¢ Removed blocking is_busy flag - now supports concurrent task processing",
    "‚Ä¢ Added priority-based task queue with semaphore-controlled concurrency",
    "‚Ä¢ Implemented connection pooling for LLM API calls",
    "‚Ä¢ Added TTL-based caching system for frequently accessed data",
    "‚Ä¢ Included circuit breaker pattern for external API reliability",
    "‚Ä¢ Background worker processes for parallel task execution"
]

for improvement in improvements:
    print(improvement)

print("\nüìä MONITORING & METRICS:")
monitoring_features = [
    "‚Ä¢ Comprehensive performance metrics collection",
    "‚Ä¢ Real-time system resource monitoring (CPU, memory)",
    "‚Ä¢ Task throughput and response time tracking",
    "‚Ä¢ Error rate calculation and trending",
    "‚Ä¢ Cache hit/miss ratio monitoring",
    "‚Ä¢ Circuit breaker status tracking"
]

for feature in monitoring_features:
    print(feature)

print("\nüîß RELIABILITY FEATURES:")
reliability_features = [
    "‚Ä¢ Automatic task retry with exponential backoff",
    "‚Ä¢ Task timeout handling with configurable limits",
    "‚Ä¢ Graceful shutdown and cleanup procedures",
    "‚Ä¢ Exception handling and error recovery",
    "‚Ä¢ Task priority queuing system",
    "‚Ä¢ Worker task management and monitoring"
]

for feature in reliability_features:
    print(feature)

print(f"\nüìÑ Implementation saved as improved_base_agent.py ({len(improved_base_agent_code)} characters)")
